{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最適なアルゴリズムやパラメータを見つける\n",
    "アヤメの分類プログラムを例に考える.  \n",
    "\n",
    "## iris.ipynbを業務に使う場合の懸念点\n",
    "1. アルゴリズムの選定   \n",
    "他にもっと高い正解率を出すアルゴリズムがあるのではないか  \n",
    "→ 各アルゴリズムの正解率を比較\n",
    "\n",
    "2. アルゴリズムの評価  \n",
    "データに対する結果に対し, ロバスト性があるのか  \n",
    "→ クロスバリデーション\n",
    "\n",
    "### クロスバリデーション(交差検証)\n",
    "複数のデータパターンで評価し, ロバスト性があるものを選択する. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifierの正解率 = 0.9333333333333333\n",
      "BaggingClassifierの正解率 = 0.9333333333333333\n",
      "BernoulliNBの正解率 = 0.26666666666666666\n",
      "CalibratedClassifierCVの正解率 = 0.7333333333333333\n",
      "CategoricalNBの正解率 = 0.9666666666666667\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_BaseChain.__init__() missing 1 required positional argument: 'base_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m all_algorithms \u001b[38;5;241m=\u001b[39m all_estimators(type_filter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (name, algorithm) \u001b[38;5;129;01min\u001b[39;00m all_algorithms:\n\u001b[0;32m---> 23\u001b[0m     clf \u001b[38;5;241m=\u001b[39m \u001b[43malgorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     clf\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[1;32m     26\u001b[0m     y_predict \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "\u001b[0;31mTypeError\u001b[0m: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'"
     ]
    }
   ],
   "source": [
    "# アルゴリズムの正解率を比較する\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "# アヤメデータの読み込み\n",
    "iris_data = pd.read_csv(\"csv/iris.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# アヤメデータをラベルと入力に分離\n",
    "y = iris_data.loc[:, \"Name\"]\n",
    "x = iris_data.loc[:, [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]]\n",
    "\n",
    "# 学習用とテスト用に分離\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, train_size=0.8, shuffle=True)\n",
    "\n",
    "#classifierのアルゴリズムを全て取得\n",
    "all_algorithms = all_estimators(type_filter=\"classifier\")\n",
    "\n",
    "for (name, algorithm) in all_algorithms:\n",
    "    clf = algorithm()\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predict = clf.predict(x_test)\n",
    "    print(\"{0}の正解率 = {1}\".format(name, accuracy_score(y_test, y_predict)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ClassifierChainではbase_estimatorの引数が必要\n",
    "→ 今回は省く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifierの正解率 = 0.9333333333333333\n",
      "BaggingClassifierの正解率 = 0.9333333333333333\n",
      "BernoulliNBの正解率 = 0.26666666666666666\n",
      "CalibratedClassifierCVの正解率 = 0.8666666666666667\n",
      "CategoricalNBの正解率 = 0.9333333333333333\n",
      "ComplementNBの正解率 = 0.7\n",
      "DecisionTreeClassifierの正解率 = 0.9333333333333333\n",
      "DummyClassifierの正解率 = 0.26666666666666666\n",
      "ExtraTreeClassifierの正解率 = 0.9333333333333333\n",
      "ExtraTreesClassifierの正解率 = 0.9333333333333333\n",
      "GaussianNBの正解率 = 0.9333333333333333\n",
      "GaussianProcessClassifierの正解率 = 0.9666666666666667\n",
      "GradientBoostingClassifierの正解率 = 0.9333333333333333\n",
      "HistGradientBoostingClassifierの正解率 = 0.9333333333333333\n",
      "KNeighborsClassifierの正解率 = 0.9666666666666667\n",
      "LabelPropagationの正解率 = 0.9333333333333333\n",
      "LabelSpreadingの正解率 = 0.9333333333333333\n",
      "LinearDiscriminantAnalysisの正解率 = 0.9666666666666667\n",
      "LinearSVCの正解率 = 0.9\n",
      "LogisticRegressionの正解率 = 0.9333333333333333\n",
      "LogisticRegressionCVの正解率 = 0.9666666666666667\n",
      "MLPClassifierの正解率 = 0.9333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassifierChain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m clf \u001b[38;5;241m=\u001b[39m \u001b[43malgorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[1;32m     28\u001b[0m y_predict \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "\u001b[0;31mTypeError\u001b[0m: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'"
     ]
    }
   ],
   "source": [
    "# アルゴリズムの正解率を比較する\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "# アヤメデータの読み込み\n",
    "iris_data = pd.read_csv(\"csv/iris.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# アヤメデータをラベルと入力に分離\n",
    "y = iris_data.loc[:, \"Name\"]\n",
    "x = iris_data.loc[:, [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]]\n",
    "\n",
    "# 学習用とテスト用に分離\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, train_size=0.8, shuffle=True)\n",
    "\n",
    "#classifierのアルゴリズムを全て取得\n",
    "all_algorithms = all_estimators(type_filter=\"classifier\")\n",
    "\n",
    "for (name, algorithm) in all_algorithms:\n",
    "    if name == 'ClassifierChain':\n",
    "        continue\n",
    "\n",
    "    clf = algorithm()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predict = clf.predict(x_test)\n",
    "    print(\"{0}の正解率 = {1}\".format(name, accuracy_score(y_test, y_predict)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "他にも変数が必要なものがある\n",
    "→ try文でエラーになる場合を無視"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifierの正解率 = 1.0\n",
      "BaggingClassifierの正解率 = 1.0\n",
      "BernoulliNBの正解率 = 0.3\n",
      "CalibratedClassifierCVの正解率 = 0.9333333333333333\n",
      "CategoricalNBの正解率 = 0.9\n",
      "ComplementNBの正解率 = 0.6\n",
      "DecisionTreeClassifierの正解率 = 0.9\n",
      "DummyClassifierの正解率 = 0.3\n",
      "ExtraTreeClassifierの正解率 = 0.9666666666666667\n",
      "ExtraTreesClassifierの正解率 = 1.0\n",
      "GaussianNBの正解率 = 1.0\n",
      "GaussianProcessClassifierの正解率 = 1.0\n",
      "GradientBoostingClassifierの正解率 = 1.0\n",
      "HistGradientBoostingClassifierの正解率 = 0.9\n",
      "KNeighborsClassifierの正解率 = 1.0\n",
      "LabelPropagationの正解率 = 1.0\n",
      "LabelSpreadingの正解率 = 1.0\n",
      "LinearDiscriminantAnalysisの正解率 = 1.0\n",
      "LinearSVCの正解率 = 0.9666666666666667\n",
      "LogisticRegressionの正解率 = 1.0\n",
      "LogisticRegressionCVの正解率 = 1.0\n",
      "MLPClassifierの正解率 = 0.9666666666666667\n",
      "MultinomialNBの正解率 = 0.8666666666666667\n",
      "NearestCentroidの正解率 = 0.9\n",
      "NuSVCの正解率 = 1.0\n",
      "PassiveAggressiveClassifierの正解率 = 0.9333333333333333\n",
      "Perceptronの正解率 = 0.9666666666666667\n",
      "QuadraticDiscriminantAnalysisの正解率 = 1.0\n",
      "RadiusNeighborsClassifierの正解率 = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifierの正解率 = 1.0\n",
      "RidgeClassifierの正解率 = 0.8666666666666667\n",
      "RidgeClassifierCVの正解率 = 0.8666666666666667\n",
      "SGDClassifierの正解率 = 0.6\n",
      "SVCの正解率 = 1.0\n"
     ]
    }
   ],
   "source": [
    "# アルゴリズムの正解率を比較する\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "# アヤメデータの読み込み\n",
    "iris_data = pd.read_csv(\"csv/iris.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# アヤメデータをラベルと入力に分離\n",
    "y = iris_data.loc[:, \"Name\"]\n",
    "x = iris_data.loc[:, [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]]\n",
    "\n",
    "# 学習用とテスト用に分離\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, train_size=0.8, shuffle=True)\n",
    "\n",
    "#classifierのアルゴリズムを全て取得\n",
    "all_algorithms = all_estimators(type_filter=\"classifier\")\n",
    "\n",
    "for (name, algorithm) in all_algorithms:\n",
    "    try:\n",
    "        clf = algorithm()\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_predict = clf.predict(x_test)\n",
    "        \n",
    "        print(\"{0}の正解率 = {1}\".format(name, accuracy_score(y_test, y_predict)))\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k分割クロスバリデーションを行う\n",
    "\n",
    "データをk個のグループに分割し, k-1個のデータを学習, 残り1つのデータで評価をk回繰り返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifierの正解率=\n",
      "[0.93333333 0.93333333 0.93333333 0.93333333 1.        ]\n",
      "BaggingClassifierの正解率=\n",
      "[0.96666667 0.9        0.9        0.96666667 1.        ]\n",
      "BernoulliNBの正解率=\n",
      "[0.3        0.33333333 0.26666667 0.3        0.23333333]\n",
      "CalibratedClassifierCVの正解率=\n",
      "[1.         0.86666667 0.96666667 0.76666667 0.86666667]\n",
      "CategoricalNBの正解率=\n",
      "[0.96666667 0.9        0.93333333 0.9        0.9       ]\n",
      "ComplementNBの正解率=\n",
      "[0.6        0.73333333 0.66666667 0.73333333 0.6       ]\n",
      "DecisionTreeClassifierの正解率=\n",
      "[0.96666667 0.93333333 0.9        0.96666667 0.93333333]\n",
      "DummyClassifierの正解率=\n",
      "[0.3        0.26666667 0.2        0.26666667 0.23333333]\n",
      "ExtraTreeClassifierの正解率=\n",
      "[0.93333333 0.9        1.         0.96666667 0.9       ]\n",
      "ExtraTreesClassifierの正解率=\n",
      "[0.96666667 0.93333333 0.9        1.         0.93333333]\n",
      "GaussianNBの正解率=\n",
      "[0.96666667 1.         0.9        0.96666667 0.93333333]\n",
      "GaussianProcessClassifierの正解率=\n",
      "[0.93333333 0.93333333 0.9        1.         0.93333333]\n",
      "GradientBoostingClassifierの正解率=\n",
      "[0.96666667 0.96666667 0.93333333 0.86666667 1.        ]\n",
      "HistGradientBoostingClassifierの正解率=\n",
      "[0.86666667 0.96666667 0.96666667 1.         0.93333333]\n",
      "KNeighborsClassifierの正解率=\n",
      "[0.93333333 1.         0.96666667 0.93333333 1.        ]\n",
      "LabelPropagationの正解率=\n",
      "[0.93333333 0.9        1.         0.96666667 1.        ]\n",
      "LabelSpreadingの正解率=\n",
      "[0.9        0.96666667 1.         0.96666667 0.93333333]\n",
      "LinearDiscriminantAnalysisの正解率=\n",
      "[0.93333333 1.         0.96666667 1.         1.        ]\n",
      "LinearSVCの正解率=\n",
      "[1.         0.96666667 0.93333333 0.9        0.96666667]\n",
      "LogisticRegressionの正解率=\n",
      "[1.         1.         0.93333333 0.9        0.96666667]\n",
      "LogisticRegressionCVの正解率=\n",
      "[0.9        1.         0.93333333 0.96666667 1.        ]\n",
      "MLPClassifierの正解率=\n",
      "[0.96666667 0.96666667 1.         1.         0.93333333]\n",
      "MultinomialNBの正解率=\n",
      "[0.93333333 0.56666667 0.86666667 0.83333333 1.        ]\n",
      "NearestCentroidの正解率=\n",
      "[0.8        0.93333333 0.96666667 1.         0.93333333]\n",
      "NuSVCの正解率=\n",
      "[0.93333333 1.         0.93333333 0.93333333 0.96666667]\n",
      "PassiveAggressiveClassifierの正解率=\n",
      "[0.96666667 0.96666667 0.9        0.93333333 0.8       ]\n",
      "Perceptronの正解率=\n",
      "[1.         0.63333333 0.63333333 0.8        0.9       ]\n",
      "QuadraticDiscriminantAnalysisの正解率=\n",
      "[0.96666667 0.9        1.         1.         1.        ]\n",
      "RadiusNeighborsClassifierの正解率=\n",
      "[0.93333333 0.96666667 0.93333333 0.96666667 0.96666667]\n",
      "RandomForestClassifierの正解率=\n",
      "[0.96666667 0.93333333 0.96666667 0.93333333 0.93333333]\n",
      "RidgeClassifierの正解率=\n",
      "[0.66666667 0.8        0.93333333 0.86666667 0.9       ]\n",
      "RidgeClassifierCVの正解率=\n",
      "[0.9        0.73333333 0.73333333 0.86666667 0.83333333]\n",
      "SGDClassifierの正解率=\n",
      "[0.73333333 1.         0.9        0.76666667 0.56666667]\n",
      "SVCの正解率=\n",
      "[0.96666667 0.93333333 1.         0.93333333 0.96666667]\n"
     ]
    }
   ],
   "source": [
    "# 5分割クロスバリデーション\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.utils import all_estimators\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# アヤメデータの読み込み\n",
    "iris_data = pd.read_csv(\"csv/iris.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# データの分離\n",
    "y = iris_data.loc[:, \"Name\"]\n",
    "x = iris_data.loc[:, [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]]\n",
    "\n",
    "# classifierのアルゴリズムを全て取得\n",
    "warnings.filterwarnings('ignore')\n",
    "all_algorithms = all_estimators(type_filter=\"classifier\")\n",
    "\n",
    "# K分割クロスバリデーション用オブジェクト\n",
    "kfold_cv = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for (name, algorithm) in all_algorithms:\n",
    "    try:\n",
    "        clf = algorithm()\n",
    "\n",
    "        # score属性を持つアルゴリズムのみを対象\n",
    "        if hasattr(clf, \"score\"):\n",
    "\n",
    "            scores = cross_val_score(clf, x, y, cv=kfold_cv)\n",
    "            print('{}の正解率='.format(name))\n",
    "            print(scores)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これはパラメータがデフォルト\n",
    "→ 最適なパラメータも見つけたい\n",
    "\n",
    "### グリッドサーチにより最適なハイパラメータを見つける\n",
    "\n",
    "#### グリッドサーチ\n",
    "ハイパラメータのチューニング手法の1つ.  \n",
    "指定したパラメータの全パターンについて, 正解率を比較し最も正解率の高いパラメータの組み合わせを選択する.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最適なパラメータ =  SVC(C=1000, gamma=0.001)\n",
      "評価時の正解率 =  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# アヤメデータの読み込み\n",
    "iris_data = pd.read_csv(\"csv/iris.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# データの分離\n",
    "y = iris_data.loc[:, \"Name\"]\n",
    "x = iris_data.loc[:, [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, train_size=0.8, shuffle=True)\n",
    "\n",
    "# グリッドサーチに使用するパラメータ\n",
    "parameters = [\n",
    "    {\"C\": [1, 10, 100, 1000], \"kernel\": [\"linear\"]},\n",
    "    {\"C\": [1, 10, 100, 1000], \"kernel\": [\"rbf\"], \"gamma\": [0.001, 0.0001]},\n",
    "    {\"C\": [1, 10, 100, 1000], \"kernel\": [\"sigmoid\"], \"gamma\": [0.001, 0.0001]}\n",
    "]\n",
    "\n",
    "# グリッドサーチ\n",
    "kfold_cv = KFold(n_splits=5, shuffle=True)\n",
    "clf = GridSearchCV(SVC(), parameters, cv=kfold_cv)\n",
    "clf.fit(x_train, y_train)\n",
    "print(\"最適なパラメータ = \", clf.best_estimator_)\n",
    "\n",
    "# 最適なパラメータの評価\n",
    "y_predict = clf.predict(x_test)\n",
    "print(\"評価時の正解率 = \", accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
